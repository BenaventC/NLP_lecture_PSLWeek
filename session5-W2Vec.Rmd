---
title: "Session 5 : Word2vec"
author: "cb,jcrm,bc,oc"
date: "`r Sys.Date()`"
output: 
  html_document :
    toc: true
    toc_float: true
    toc_depth: 3
---

# Tools

```{r setup, include=TRUE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, include=TRUE, message=FALSE, warning=FALSE)
#from session 1 & 2
library(tidyverse)
library(udpipe)
library(flextable)
library(cowplot)
library(quanteda)
library(quanteda.textmodels)
library(quanteda.textstats)
library(quanteda.textplots)
library(syuzhet)  #analyse du sentimeent

# new for session 3
library(FactoMineR)
library(factoextra)
library(igraph)
library(ggwordcloud)
library(ggrepel)

library(Rtsne)
library(tidytext)

#new for session 5
library(word2vec)
library(ape)

theme_set(theme_minimal()+theme(plot.title = element_text(size=12)))

t1=Sys.time()

```

# Building embeddings

```{r 01}
UD<-readRDS("./data/UD.rds")

#on filtre adverbes adjectifs verb et non communs
updated_vocab <- UD %>%  
  filter(upos %in% c('NOUN', 'PROPN', "ADJ", "ADV","VERB")) %>% 
  mutate(lemma=tolower(lemma))

updated_vocab2<- updated_vocab %>%
  group_by(lemma)%>%
  summarise(n=n())

#on reconstitue le texte filtr√©
text2<-updated_vocab %>%
 group_by(doc_id) %>%
 summarise(description = paste(lemma, collapse = " "))


#on vectorise
set.seed(123456789)
model <- word2vec(x = text2$description, 
                  type = "skip-gram", 
                  window = 20, 
                  dim = 200, 
                  iter = 100
                  )
embedding <- as.matrix(model)

#test sur review
lookslike <- predict(model, c("lda"), type = "nearest", top_n = 20)
lookslike
```


# Text as vectors

# An application to ML

# conclusion : from vector to transformer. 

