#spécifier l'optimisateur
optimizer <- optim_adam(params = model$parameters, lr = 0.005, weight_decay = 0.0000012)
#définir la fonction d'érreur
loss      <- model$fit(data = dtm, optimizer = optimizer, epoch = 30, batch_size = 3000)
#définir la fonction d'érreur
loss      <- model$fit(data = dtm, optimizer = optimizer, epoch = 30, batch_size = 1000)
dtm   <- strsplit.data.frame(x, group = "doc_id", term = "text", split = " ")
dim(dtm)
dtm   <- document_term_frequencies(dtm)
dim(dtm)
dtm   <- document_term_matrix(dtm)
dim(dtm)
dtm   <- dtm_remove_tfidf(dtm, prob=0.5)
dim(dtm)
vocab        <- intersect(rownames(embeddings), colnames(dtm))
embeddings   <- dtm_conform(embeddings, rows = vocab)
dtm          <- dtm_conform(dtm,     columns = vocab)
dim(dtm)
dim(embeddings)
# on injecte le dtm dans le topic model
#k : le nombre de topic
#dim : une dim ? 800 par défaut
set.seed(1234)
#pour la reproducibility
torch_manual_seed(4321)
#spécifier le modèle
model     <- ETM(k = 20, dim = 100, embeddings = embeddings)
#spécifier l'optimisateur
optimizer <- optim_adam(params = model$parameters, lr = 0.005, weight_decay = 0.0000012)
#définir la fonction d'érreur
loss      <- model$fit(data = dtm, optimizer = optimizer, epoch = 30, batch_size = 1000)
#définir la fonction d'érreur
loss      <- model$fit(data = dtm, optimizer = optimizer, epoch = 30, batch_size = 10000)
#définir la fonction d'érreur
loss      <- model$fit(data = dtm, optimizer = optimizer, epoch = 25, batch_size = 2000)
View(embeddings)
#spécifier le modèle
model     <- ETM(k = 20, dim = 200, embeddings = embeddings)
#spécifier l'optimisateur
optimizer <- optim_adam(params = model$parameters, lr = 0.005, weight_decay = 0.0000012)
#définir la fonction d'érreur
loss      <- model$fit(data = dtm, optimizer = optimizer, epoch = 25, batch_size = 2000)
library(torch) #nécessaire pour le tiopic
library(topicmodels.etm) #le topic original
# on injecte le dtm dans le topic model
#k : le nombre de topic
#dim : une dim ? 800 par défaut
set.seed(1234)
#pour la reproducibility
torch_manual_seed(4321)
#spécifier le modèle
model     <- ETM(k = 20, dim = 200, embeddings = embeddings)
#spécifier l'optimisateur
optimizer <- optim_adam(params = model$parameters, lr = 0.005, weight_decay = 0.0000012)
#définir la fonction d'érreur
loss      <- model$fit(data = dtm, optimizer = optimizer, epoch = 25, batch_size = 2000)
#spécifier l'optimisateur
optimizer <- optim_adam(params = model$parameters, lr = 0.001, weight_decay = 0.000002)
#définir la fonction d'érreur
loss      <- model$fit(data = dtm, optimizer = optimizer, epoch = 25, batch_size = 2000)
#définir la fonction d'érreur
loss      <- model$fit(data = dtm, optimizer = optimizer, epoch = 25, batch_size = 1000)
dtm   <- strsplit.data.frame(x, group = "doc_id", term = "text", split = " ")
dim(dtm)
dtm   <- document_term_frequencies(dtm)
dim(dtm)
dtm   <- document_term_matrix(dtm)
dim(dtm)
dtm   <- dtm_remove_tfidf(dtm, prob=0.55)
dim(dtm)
vocab        <- intersect(rownames(embeddings), colnames(dtm))
embeddings   <- dtm_conform(embeddings, rows = vocab)
dtm          <- dtm_conform(dtm,     columns = vocab)
dim(dtm)
dim(embeddings)
# on injecte le dtm dans le topic model
#k : le nombre de topic
#dim : une dim ? 800 par défaut
set.seed(1234)
#pour la reproducibility
torch_manual_seed(4321)
#spécifier le modèle
model     <- ETM(k = 20, dim = 200, embeddings = embeddings)
#spécifier l'optimisateur
optimizer <- optim_adam(params = model$parameters, lr = 0.001, weight_decay = 0.000002)
#définir la fonction d'érreur
loss      <- model$fit(data = dtm, optimizer = optimizer, epoch = 25, batch_size = 1000)
#pour observer la convergence
plot(model, type = "loss")
plot(model, type = "topics")
terminology  <- predict(model, type = "terms", top_n = 15)
topic<-bind_rows(terminology, .id = "id")
library(ggwordcloud)
ggplot(topic, aes(label = term, size = beta)) +
geom_text_wordcloud_area() + facet_wrap(vars(id))+
scale_size_area(max_size = 7) +
theme_minimal()
manifolded <- summary(model, type = "umap", n_components = 2, metric = "cosine", n_neighbors = 10,
fast_sgd = FALSE, n_threads = 2, verbose = TRUE)
space <- subset(manifolded$embed_2d, type %in% "centers")
View(space)
manifolded <- summary(model, type = "umap", n_components = 2, metric = "cosine", n_neighbors = 10,
fast_sgd = FALSE, n_threads = 2, verbose = TRUE)
space <- subset(manifolded$embed_2d, type %in% "centers")
textplot_embedding_2d(space)
space      <- subset(manifolded$embed_2d, cluster %in% c(1,2,3,4,5,6,7,8,9,10,11,12) & rank <= 25)
textplot_embedding_2d(space, title = "ETM topics", subtitle = "embedded in 2D using UMAP",
encircle = FALSE, points = TRUE)
space$topic <- factor(space$cluster)
View(space)
plt <- ggplot(space, aes(x = x, y = y, label = term, color = topic, size =3, pch = factor(type, levels = c("centers", "words")))) +
geom_text_repel(show.legend = FALSE, max.overlaps	=50, size=2.5) +
#    theme_void() +
labs(title = "ETM topics", subtitle = "embedded in 2D using UMAP")
plt + geom_point(show.legend = FALSE)+theme_bw()
space      <- subset(manifolded$embed_2d, cluster %in% c(1,2,3,4,5,6,7,8,9,10,11,12) & rank <= 10)
textplot_embedding_2d(space, title = "ETM topics", subtitle = "embedded in 2D using UMAP",
encircle = FALSE, points = TRUE)
space$topic <- factor(space$cluster)
plt <- ggplot(space, aes(x = x, y = y, label = term, color = topic, size =3, pch = factor(type, levels = c("centers", "words")))) +
geom_text_repel(show.legend = FALSE, max.overlaps	=50, size=2.5) +
#    theme_void() +
labs(title = "ETM topics", subtitle = "embedded in 2D using UMAP")
plt + geom_point(show.legend = FALSE)+theme_bw()
manifolded <- summary(model, type = "umap", n_components = 2, metric = "cosine", n_neighbors = 10,
fast_sgd = FALSE, n_threads = 2, verbose = TRUE)
space <- subset(manifolded$embed_2d, type %in% "centers")
#textplot_embedding_2d(space)
plt <- ggplot(space, aes(x = x, y = y, label = term, color = term, size =3)) +
geom_text_repel(show.legend = FALSE, max.overlaps	=50, size=2.5) +
#    theme_void() +
labs(title = "ETM topics", subtitle = "embedded in 2D using UMAP")
plt + geom_point(show.legend = FALSE)+theme_bw()
#textplot_embedding_2d(space)
plt <- ggplot(space, aes(x = x, y = y, label = term, color = term, size =2)) +
geom_text_repel(show.legend = FALSE, max.overlaps	=50, size=2.5) +
#    theme_void() +
labs(title = "ETM topics", subtitle = "embedded in 2D using UMAP")
plt + geom_point(show.legend = FALSE)+theme_bw()
#textplot_embedding_2d(space)
plt <- ggplot(space, aes(x = x, y = y, label = term, color = term, size =1)) +
geom_text_repel(show.legend = FALSE, max.overlaps	=50, size=2.5) +
#    theme_void() +
labs(title = "ETM topics", subtitle = "embedded in 2D using UMAP")
plt + geom_point(show.legend = FALSE)+theme_bw()
plt + geom_point(show.legend = FALSE, size=2)+theme_bw()
#textplot_embedding_2d(space)
plt <- ggplot(space, aes(x = x, y = y, label = term, color = term, size =1)) +
geom_text_repel(show.legend = FALSE, max.overlaps	=50, size=3) +
#    theme_void() +
labs(title = "ETM topics", subtitle = "embedded in 2D using UMAP")+
geom_point(show.legend = FALSE, size=2)+theme_bw()
#textplot_embedding_2d(space)
plt <- ggplot(space, aes(x = x, y = y, label = term, color = term, size =1)) +
geom_text_repel(show.legend = FALSE, max.overlaps	=50, size=3) +
#    theme_void() +
labs(title = "ETM topics", subtitle = "embedded in 2D using UMAP")+
geom_point(show.legend = FALSE, size=2)+theme_bw()
plt
space      <- subset(manifolded$embed_2d, cluster %in% c(1,5,12) & rank <= 10)
textplot_embedding_2d(space, title = "ETM topics", subtitle = "embedded in 2D using UMAP",
encircle = FALSE, points = TRUE)
space$topic <- factor(space$cluster)
plt <- ggplot(space, aes(x = x, y = y, label = term, color = topic, size =3, pch = factor(type, levels = c("centers", "words")))) +
geom_text_repel(show.legend = FALSE, max.overlaps	=50, size=2.5) +
#    theme_void() +
labs(title = "ETM topics", subtitle = "embedded in 2D using UMAP")
plt + geom_point(show.legend = FALSE)+theme_bw()
## encircle if topics are non-overlapping can provide nice visualisations
library(ggalt)
plt + geom_encircle(aes(group = topic, fill = topic), alpha = 0.4, show.legend = FALSE) + geom_point(show.legend = FALSE)
space      <- subset(manifolded$embed_2d, cluster %in% c(1) & rank <= 10)
textplot_embedding_2d(space, title = "ETM topics", subtitle = "embedded in 2D using UMAP",
encircle = FALSE, points = TRUE)
space$topic <- factor(space$cluster)
plt <- ggplot(space, aes(x = x, y = y, label = term, color = topic, size =3, pch = factor(type, levels = c("centers", "words")))) +
geom_text_repel(show.legend = FALSE, max.overlaps	=50, size=2.5) +
#    theme_void() +
labs(title = "ETM topics", subtitle = "embedded in 2D using UMAP")
plt + geom_point(show.legend = FALSE)+theme_bw()
space      <- subset(manifolded$embed_2d, cluster %in% c(12) & rank <= 10)
textplot_embedding_2d(space, title = "ETM topics", subtitle = "embedded in 2D using UMAP",
encircle = FALSE, points = TRUE)
space$topic <- factor(space$cluster)
plt <- ggplot(space, aes(x = x, y = y, label = term, color = topic, size =3, pch = factor(type, levels = c("centers", "words")))) +
geom_text_repel(show.legend = FALSE, max.overlaps	=50, size=2.5) +
#    theme_void() +
labs(title = "ETM topics", subtitle = "embedded in 2D using UMAP")
plt + geom_point(show.legend = FALSE)+theme_bw()
## encircle if topics are non-overlapping can provide nice visualisations
plt + geom_encircle(aes(group = topic, fill = topic), alpha = 0.4, show.legend = FALSE) + geom_point(show.legend = FALSE)
ggsave("mtcars.jpeg",plot=last_plot(), width = 28, height = 20, units = "cm")
knitr::opts_chunk$set(echo = TRUE)
text=c("Je n'aime pas la politique mais je suis prêt à en accepter les responsabilité",
"la vie est question de pouvoir même on on ne l'aime pas")
install.packages("transforEmotion")
library(transforEmotion)
text=c("Je n'aime pas la politique mais je suis prêt à en accepter les responsabilité",
"la vie est question de pouvoir même on on ne l'aime pas")
# Directly from huggingface: typeform/distilbert-base-uncased-mnli
scores<-transformer_scores(
text = text,
classes = c(
"politique", "pouvoir", "société" ),
transformer = "BaptisteDoyen/camembert-base-xnli"
)
# Directly from huggingface: typeform/distilbert-base-uncased-mnli
scores<-transformer_scores(
text = text,
classes = c(
"politique", "pouvoir", "société" ),
)
text=c("Je n'aime pas la politique mais je suis prêt à en accepter les responsabilité",
"la vie est question de pouvoir même on on ne l'aime pas")
# Directly from huggingface: typeform/distilbert-base-uncased-mnli
scores<-transformer_scores(
text = text,
classes = c(
"politique", "pouvoir", "société" ),
)
knitr::opts_chunk$set(echo = TRUE)
# install.packages("devtools")
devtools::install_github("oscarkjell/text")
# install.packages("devtools")
devtools::install_github("oscarkjell/text")
library(text)
# install.packages("devtools")
install.packages("text")
install.packages("text")
install.packages("text")
knitr::opts_chunk$set(echo = TRUE)
library(text)
install.packages("parsnip")
install.packages("parsnip")
knitr::opts_chunk$set(echo = TRUE)
library(text)
install.packages("parsnip", dependencies = FALSE)
install.packages("hardhat", dependencies = FALSE)
install.packages("vctrs", dependencies = FALSE)
remove("vctrs")
install.packages("vctrs", dependencies = FALSE)
install.packages("vctrs", dependencies = FALSE)
remove(vctrs)
remove.packages(vctrs)
remove.packages("vctrs")
install.packages("vctrs", dependencies = FALSE)
install.packages("vctrs", dependencies = FALSE)
install.packages("vctrs", dependencies = FALSE)
install.packages("vctrs", dependencies = FALSE)
install.packages("vctrs", dependencies = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(text)
install.packages("parsnip", dependencies = FALSE)
install.packages("hardhat", dependencies = FALSE)
remove.packages("glue")
install.packages("glue", dependencies = FALSE)
install.packages("glue", dependencies = FALSE)
remove.packages("glue")
install.packages("glue", dependencies = FALSE)
install.packages("glue", dependencies = FALSE)
install.packages("hardhat", dependencies = FALSE)
remove.packages("tibble")
install.packages("tibble", dependencies = FALSE)
install.packages("hardhat", dependencies = FALSE)
install.packages("tibble", dependencies = FALSE)
install.packages("hardhat", dependencies = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(text)
install.packages("parsnip", dependencies = FALSE)
library(text)
install.packages("recipes", dependencies = FALSE)
library(text)
install.packages("tune", dependencies = FALSE)
install.packages("dials", dependencies = FALSE)
install.packages("workflows", dependencies = FALSE)
install.packages("tune", dependencies = FALSE)
library(text)
install.packages("tune", dependencies = FALSE)
remove.packages("cli")
install.packages("cli", dependencies = FALSE)
install.packages("cli", dependencies = FALSE)
remove.packages("cli")
install.packages("cli", dependencies = FALSE)
install.packages("cli", dependencies = FALSE)
install.packages("tune", dependencies = FALSE)
install.packages("tune", dependencies = FALSE)
install.packages("cli", dependencies = FALSE)
install.packages("cli", dependencies = FALSE)
install.packages("tune", dependencies = FALSE)
remove.packages("dplyr")
install.packages("dplyr", dependencies = FALSE)
install.packages("tune", dependencies = FALSE)
remove.packages("yardsticl")
remove.packages("yardstick")
install.packages("yardstick", dependencies = FALSE)
install.packages("tune", dependencies = FALSE)
install.packages("yardstick", dependencies = FALSE)
remove.packages("dplyr")
install.packages("dplyr", dependencies = FALSE)
install.packages("yardstick", dependencies = FALSE)
install.packages("tune", dependencies = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(text)
# Install text required python packages in a conda environment (with defaults).
textrpp_install()
# Initialize the installed conda environment.
# save_profile = TRUE saves the settings so that you don't have to run textrpp_initialize() after restarting R.
textrpp_initialize(save_profile = TRUE)
# Install text required python packages in a conda environment (with defaults).
textrpp_install()
# Initialize the installed conda environment.
# save_profile = TRUE saves the settings so that you don't have to run textrpp_initialize() after restarting R.
textrpp_initialize(save_profile = TRUE)
# Initialize the installed conda environment.
# save_profile = TRUE saves the settings so that you don't have to run textrpp_initialize() after restarting R.
textrpp_initialize(save_profile = TRUE)
wordembeddings <- textEmbed(Language_based_assessment_data_8,
model = 'bert-base-uncased')
library(text)
# Install text required python packages in a conda environment (with defaults).
textrpp_install()
# Initialize the installed conda environment.
# save_profile = TRUE saves the settings so that you don't have to run textrpp_initialize() after restarting R.
textrpp_initialize(save_profile = TRUE)
knitr::opts_chunk$set(echo = TRUE)
# install.packages("devtools")
#install.packages("text")
library(text)
# Install text required python packages in a conda environment (with defaults).
textrpp_install()
# save_profile = TRUE saves the settings so that you don't have to run textrpp_initialize() after restarting R.
textrpp_initialize() #save_profile = TRUE
# save_profile = TRUE saves the settings so that you don't have to run textrpp_initialize() after restarting R.
textrpp_initialize(save_profile = TRUE) #
# Install text required python packages in a conda environment (with defaults).
textrpp_install()
# save_profile = TRUE saves the settings so that you don't have to run textrpp_initialize() after restarting R.
textrpp_initialize(textrpp_condaenv,save_profile = TRUE) #
wordembeddings <- textEmbed(Language_based_assessment_data_8,
model = 'bert-base-uncased')
library(transforEmotion)
text=c("Je n'aime pas la politique mais je suis prêt à en accepter les responsabilité",
"la vie est question de pouvoir même on on ne l'aime pas")
# Directly from huggingface: typeform/distilbert-base-uncased-mnli
scores<-transformer_scores(
text = text,
classes = c(
"politique", "pouvoir", "société" ),
)
# install.packages("devtools")
devtools::install_github(
"jonathanbratt/RBERT",
build_vignettes = TRUE
)
# install.packages("devtools")
devtools::install_github(
"jonathanbratt/RBERT",
build_vignettes = TRUE
)
remove(tensorflow)
tensorflow::install_tensorflow(version = "1.13.1")
install.packages("tensorflow", dependencies = FALSE)
remove(reticulate)
install.packages("reticulate", dependencies = FALSE)
knitr::opts_chunk$set(echo = TRUE)
# install.packages("devtools")
devtools::install_github(
"jonathanbratt/RBERT",
build_vignettes = TRUE
)
devtools::install_github("rstudio/reticulate")
remove(reticulate)
devtools::install_github("rstudio/reticulate")
remove(reticulate)
knitr::opts_chunk$set(echo = TRUE)
# install.packages("devtools")
devtools::install_github(
"jonathanbratt/RBERT",
build_vignettes = TRUE
)
devtools::install_github("rstudio/reticulate")
remove(Rccp)
remove(rccp)
# install.packages("rccp")
install.packages("rccp")
devtools::install_github("rstudio/reticulate")
remove(Rccp)
remove.packages(Rccp)
install.packages("Rccp")
devtools::install_github("rstudio/reticulate")
library(reticulate)
tensorflow::install_tensorflow(version = "1.13.1")
knitr::opts_chunk$set(echo = TRUE)
library(RBERT)
library(dplyr)
# Download pre-trained BERT model. This will go to an appropriate cache
# directory by default.
BERT_PRETRAINED_DIR <- RBERT::download_BERT_checkpoint(
model = "bert_base_uncased"
)
text_to_process <- c("Impulse is equal to the change in momentum.",
"Changing momentum requires an impulse.",
"An impulse is like a push.",
"Impulse is force times time.")
# Or make two-segment examples:
text_to_process2 <- list(c("Impulse is equal to the change in momentum.",
"Changing momentum requires an impulse."),
c("An impulse is like a push.",
"Impulse is force times time."))
BERT_feats <- extract_features(
examples = text_to_process2,
ckpt_dir = BERT_PRETRAINED_DIR,
layer_indexes = 1:12
)
BERT_feats <- extract_features(
examples = text_to_process2,
ckpt_dir = BERT_PRETRAINED_DIR,
layer_indexes = 1:12
)
BERT_feats <- extract_features(
examples = text_to_process,
ckpt_dir = BERT_PRETRAINED_DIR,
layer_indexes = 1:12
)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(udpipe)
library(flextable)
library(readr)
df <- read_csv("data_original_12062022_normalise_sentiment_transformers_lemna_words_adj.csv")%>%
select (id, date_ecrit, titre, description, ressenti, pays,intitule, canaux_typologie_1, transformer_sentiment_score, lem_words,lem_adj)
foo<-df%>%
filter(intitule=="Réseau consulaire")
saveRDS(foo, "exp_consulat.rds")
typo<-as.data.frame(str_split_fixed(df$canaux_typologie_1, ",", 10))%>%
mutate(across(where(is.character), str_trim)) %>%
cbind(df$id) %>%
rename(id=11) %>%
pivot_longer(-id, names_to = "valeur", values_to="variable") %>%
filter(variable!="") %>% group_by(id, variable) %>%
summarise(valeur=1) %>%
pivot_wider(id,names_from="variable", values_from="valeur")%>%
replace(is.na(.), 0)
n_c<-nrow(typo)
foo<-typo %>%
pivot_longer(-id, names_to = "variable", values_to="value") %>%
group_by(variable)%>%
summarise(Penetration=mean(value))
ggplot(foo, aes(x=reorder(variable, Penetration),y=Penetration))+
geom_bar(stat="identity",fill="firebrick")+
coord_flip()
#typo
foo<-typo%>%select(-id,-12)
#service
table(df$intitule)
#service
t<-as.data.frame(table(df$intitule)) %>%filter(Freq>50)
ggplot(t, aes(x=reorder(Var1, Freq),y=Freq))+
geom_bar(stat="identity",fill="firebrick")+
coord_flip()
foo<-df%>%mutate(n=1)%>%group_by(intitule)%>%summarise(score=mean(transformer_sentiment_score,na.rm=TRUE),n=sum(n)) %>% filter(n>50)
ggplot(foo, aes(x=reorder(intitule, n), y=score ))+  geom_bar(stat="identity",fill="firebrick")+
coord_flip()
library(readr)
df <- read_csv("data_original_12062022_normalise_sentiment_transformers_lemna_words_adj.csv")%>%
select (id, date_ecrit, titre, description, ressenti, pays,intitule, canaux_typologie_1, transformer_sentiment_score, lem_words,lem_adj)
foo<-df%>%
filter(intitule=="Réseau consulaire")
saveRDS(foo, "exp_consulat.rds")
typo<-as.data.frame(str_split_fixed(df$canaux_typologie_1, ",", 10))%>%
mutate(across(where(is.character), str_trim)) %>%
cbind(df$id) %>%
rename(id=11) %>%
pivot_longer(-id, names_to = "valeur", values_to="variable") %>%
filter(variable!="") %>%
group_by(id, variable) %>%
summarise(valeur=1) %>%
pivot_wider(id,names_from="variable", values_from="valeur")%>%
replace(is.na(.), 0)
n_c<-nrow(typo)
foo<-typo %>%
pivot_longer(-id, names_to = "variable", values_to="value") %>%
group_by(variable)%>%
summarise(Penetration=mean(value))
ggplot(foo, aes(x=reorder(variable, Penetration),y=Penetration))+
geom_bar(stat="identity",fill="firebrick")+
coord_flip()
#typo
foo<-typo%>%select(-id,-12)
#service
table(df$intitule)
#service
t<-as.data.frame(table(df$intitule)) %>%filter(Freq>50)
ggplot(t, aes(x=reorder(Var1, Freq),y=Freq))+
geom_bar(stat="identity",fill="firebrick")+
coord_flip()
foo<-df%>%mutate(n=1)%>%group_by(intitule)%>%summarise(score=mean(transformer_sentiment_score,na.rm=TRUE),n=sum(n)) %>% filter(n>50)
ggplot(foo, aes(x=reorder(intitule, n), y=score ))+  geom_bar(stat="identity",fill="firebrick")+
coord_flip()
knitr::opts_chunk$set(echo = TRUE, include=TRUE, message=FALSE, warning=FALSE)
library(tidyverse)
library(udpipe)
library(flextable)
df <- read_csv("data_original_12062022_normalise_sentiment_transformers_lemna_words_adj.csv")%>%
select (id, date_ecrit, titre, description, ressenti, pays,intitule, canaux_typologie_1, transformer_sentiment_score, lem_words,lem_adj)
df <- read_csv("data_original_12062022_normalise_sentiment_transformers_lemna_words_adj.csv")%>%
select (id, date_ecrit, titre, description, ressenti, pays,intitule, canaux_typologie_1, transformer_sentiment_score, lem_words,lem_adj)
ggplot(df,aes(x=transformer_sentiment_score))+geom_density()
ggplot(df, aes(x=transformer_sentiment_score)) +
stat_ecdf(geom = "step")
ggplot(df, aes(x=transformer_sentiment_score)) +
stat_ecdf(geom = "step")+xlim(0,1)
